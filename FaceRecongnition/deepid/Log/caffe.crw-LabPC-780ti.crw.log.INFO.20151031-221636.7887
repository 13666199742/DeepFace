Log file created at: 2015/10/31 22:16:36
Running on machine: crw-LabPC-780ti
Log line format: [IWEF]mmdd hh:mm:ss.uuuuuu threadid file:line] msg
I1031 22:16:36.802520  7887 caffe.cpp:113] Use GPU with device ID 0
I1031 22:16:37.016144  7887 caffe.cpp:121] Starting Optimization
I1031 22:16:37.031692  7887 solver.cpp:32] Initializing solver from parameters: 
test_iter: 100
test_interval: 1000
base_lr: 0.001
display: 100
max_iter: 5000000
lr_policy: "step"
gamma: 0.95
momentum: 0.9
weight_decay: 0.0005
stepsize: 100000
snapshot: 50000
snapshot_prefix: "/media/crw/MyBook/Model/FaceRecognition/try5_2/snapshot"
solver_mode: GPU
device_id: 0
net: "FaceRecognition/try5_2/train_val.prototxt"
I1031 22:16:37.035120  7887 solver.cpp:70] Creating training net from net file: FaceRecognition/try5_2/train_val.prototxt
I1031 22:16:37.036387  7887 net.cpp:287] The NetState phase (0) differed from the phase (1) specified by a rule in layer data_1
I1031 22:16:37.036414  7887 net.cpp:287] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy_1
I1031 22:16:37.036523  7887 net.cpp:42] Initializing net from parameters: 
name: "face_train_val"
state {
  phase: TRAIN
}
layer {
  name: "data_1"
  type: "Data"
  top: "data_1"
  top: "label_1"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    mean_file: "/media/crw/MyBook/TrainData/LMDB/CASIA-WebFace/10575_64X64/mean.binaryproto"
  }
  data_param {
    source: "/media/crw/MyBook/TrainData/LMDB/CASIA-WebFace/10575_64X64/train"
    batch_size: 32
    backend: LMDB
  }
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "data_1"
  top: "conv1_1"
  param {
    name: "conv1_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv1_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 20
    kernel_size: 4
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1"
  top: "conv1_1"
}
layer {
  name: "norm1_1"
  type: "LRN"
  bottom: "conv1_1"
  top: "norm1_1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool1_1"
  type: "Pooling"
  bottom: "norm1_1"
  top: "pool1_1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1_1"
  top: "conv2_1"
  param {
    name: "conv2_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv2_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 40
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "norm2_1"
  type: "LRN"
  bottom: "conv2_1"
  top: "norm2_1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool2_1"
  type: "Pooling"
  bottom: "norm2_1"
  top: "pool2_1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2_1"
  top: "conv3_1"
  param {
    name: "conv3_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv3_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 60
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "pool3_1"
  type: "Pooling"
  bottom: "conv3_1"
  top: "pool3_1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3_1"
  top: "conv4_1"
  param {
    name: "conv4_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv4_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 80
    kernel_size: 2
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "flatten_pool3_1"
  type: "Flatten"
  bottom: "pool3_1"
  top: "flatten_pool3_1"
}
layer {
  name: "flatten_conv4_1"
  type: "Flatten"
  bottom: "conv4_1"
  top: "flatten_conv4_1"
}
layer {
  name: "contact_conv"
  type: "Concat"
  bottom: "flatten_conv4_1"
  bottom: "flatten_pool3_1"
  top: "contact_conv"
}
layer {
  name: "deepid_1"
  type: "InnerProduct"
  bottom: "contact_conv"
  top: "deepid_1"
  param {
    name: "fc6_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "fc6_b"
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 160
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6_1"
  type: "ReLU"
  bottom: "deepid_1"
  top: "deepid_1"
}
layer {
  name: "drop6_1"
  type: "Dropout"
  bottom: "deepid_1"
  top: "deepid_1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8_1"
  type: "InnerProduct"
  bottom: "deepid_1"
  top: "fc8_1"
  param {
    name: "fc8_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "fc8_b"
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 10575
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss_1"
  type: "SoftmaxWithLoss"
  bottom: "fc8_1"
  bottom: "label_1"
  top: "loss_1"
}
I1031 22:16:37.037242  7887 layer_factory.hpp:74] Creating layer data_1
I1031 22:16:37.048558  7887 net.cpp:90] Creating Layer data_1
I1031 22:16:37.048576  7887 net.cpp:368] data_1 -> data_1
I1031 22:16:37.048601  7887 net.cpp:368] data_1 -> label_1
I1031 22:16:37.048616  7887 net.cpp:120] Setting up data_1
I1031 22:16:37.049530  7887 db.cpp:34] Opened lmdb /media/crw/MyBook/TrainData/LMDB/CASIA-WebFace/10575_64X64/train
I1031 22:16:37.049585  7887 data_layer.cpp:67] output data size: 32,3,64,64
I1031 22:16:37.049599  7887 data_transformer.cpp:22] Loading mean file from: /media/crw/MyBook/TrainData/LMDB/CASIA-WebFace/10575_64X64/mean.binaryproto
I1031 22:16:37.050922  7887 net.cpp:127] Top shape: 32 3 64 64 (393216)
I1031 22:16:37.050947  7887 net.cpp:127] Top shape: 32 (32)
I1031 22:16:37.050962  7887 layer_factory.hpp:74] Creating layer conv1_1
I1031 22:16:37.051192  7887 net.cpp:90] Creating Layer conv1_1
I1031 22:16:37.051211  7887 net.cpp:410] conv1_1 <- data_1
I1031 22:16:37.051235  7887 net.cpp:368] conv1_1 -> conv1_1
I1031 22:16:37.051259  7887 net.cpp:120] Setting up conv1_1
I1031 22:16:37.052197  7887 net.cpp:127] Top shape: 32 20 61 61 (2381440)
I1031 22:16:37.052228  7887 layer_factory.hpp:74] Creating layer relu1_1
I1031 22:16:37.052250  7887 net.cpp:90] Creating Layer relu1_1
I1031 22:16:37.052263  7887 net.cpp:410] relu1_1 <- conv1_1
I1031 22:16:37.052276  7887 net.cpp:357] relu1_1 -> conv1_1 (in-place)
I1031 22:16:37.052290  7887 net.cpp:120] Setting up relu1_1
I1031 22:16:37.052306  7887 net.cpp:127] Top shape: 32 20 61 61 (2381440)
I1031 22:16:37.052322  7887 layer_factory.hpp:74] Creating layer norm1_1
I1031 22:16:37.052350  7887 net.cpp:90] Creating Layer norm1_1
I1031 22:16:37.052372  7887 net.cpp:410] norm1_1 <- conv1_1
I1031 22:16:37.052397  7887 net.cpp:368] norm1_1 -> norm1_1
I1031 22:16:37.052425  7887 net.cpp:120] Setting up norm1_1
I1031 22:16:37.052459  7887 net.cpp:127] Top shape: 32 20 61 61 (2381440)
I1031 22:16:37.052480  7887 layer_factory.hpp:74] Creating layer pool1_1
I1031 22:16:37.052510  7887 net.cpp:90] Creating Layer pool1_1
I1031 22:16:37.052534  7887 net.cpp:410] pool1_1 <- norm1_1
I1031 22:16:37.052557  7887 net.cpp:368] pool1_1 -> pool1_1
I1031 22:16:37.052583  7887 net.cpp:120] Setting up pool1_1
I1031 22:16:37.052614  7887 net.cpp:127] Top shape: 32 20 31 31 (615040)
I1031 22:16:37.052629  7887 layer_factory.hpp:74] Creating layer conv2_1
I1031 22:16:37.052647  7887 net.cpp:90] Creating Layer conv2_1
I1031 22:16:37.052661  7887 net.cpp:410] conv2_1 <- pool1_1
I1031 22:16:37.052675  7887 net.cpp:368] conv2_1 -> conv2_1
I1031 22:16:37.052691  7887 net.cpp:120] Setting up conv2_1
I1031 22:16:37.052850  7887 net.cpp:127] Top shape: 32 40 29 29 (1076480)
I1031 22:16:37.052868  7887 layer_factory.hpp:74] Creating layer relu2_1
I1031 22:16:37.052901  7887 net.cpp:90] Creating Layer relu2_1
I1031 22:16:37.052913  7887 net.cpp:410] relu2_1 <- conv2_1
I1031 22:16:37.052927  7887 net.cpp:357] relu2_1 -> conv2_1 (in-place)
I1031 22:16:37.052940  7887 net.cpp:120] Setting up relu2_1
I1031 22:16:37.052953  7887 net.cpp:127] Top shape: 32 40 29 29 (1076480)
I1031 22:16:37.052964  7887 layer_factory.hpp:74] Creating layer norm2_1
I1031 22:16:37.052978  7887 net.cpp:90] Creating Layer norm2_1
I1031 22:16:37.052989  7887 net.cpp:410] norm2_1 <- conv2_1
I1031 22:16:37.053001  7887 net.cpp:368] norm2_1 -> norm2_1
I1031 22:16:37.053015  7887 net.cpp:120] Setting up norm2_1
I1031 22:16:37.053030  7887 net.cpp:127] Top shape: 32 40 29 29 (1076480)
I1031 22:16:37.053041  7887 layer_factory.hpp:74] Creating layer pool2_1
I1031 22:16:37.053058  7887 net.cpp:90] Creating Layer pool2_1
I1031 22:16:37.053072  7887 net.cpp:410] pool2_1 <- norm2_1
I1031 22:16:37.053086  7887 net.cpp:368] pool2_1 -> pool2_1
I1031 22:16:37.053099  7887 net.cpp:120] Setting up pool2_1
I1031 22:16:37.053114  7887 net.cpp:127] Top shape: 32 40 15 15 (288000)
I1031 22:16:37.053125  7887 layer_factory.hpp:74] Creating layer conv3_1
I1031 22:16:37.053139  7887 net.cpp:90] Creating Layer conv3_1
I1031 22:16:37.053150  7887 net.cpp:410] conv3_1 <- pool2_1
I1031 22:16:37.053164  7887 net.cpp:368] conv3_1 -> conv3_1
I1031 22:16:37.053179  7887 net.cpp:120] Setting up conv3_1
I1031 22:16:37.053992  7887 net.cpp:127] Top shape: 32 60 13 13 (324480)
I1031 22:16:37.054009  7887 layer_factory.hpp:74] Creating layer pool3_1
I1031 22:16:37.054023  7887 net.cpp:90] Creating Layer pool3_1
I1031 22:16:37.054034  7887 net.cpp:410] pool3_1 <- conv3_1
I1031 22:16:37.054047  7887 net.cpp:368] pool3_1 -> pool3_1
I1031 22:16:37.054060  7887 net.cpp:120] Setting up pool3_1
I1031 22:16:37.054077  7887 net.cpp:127] Top shape: 32 60 7 7 (94080)
I1031 22:16:37.054090  7887 layer_factory.hpp:74] Creating layer pool3_1_pool3_1_0_split
I1031 22:16:37.054105  7887 net.cpp:90] Creating Layer pool3_1_pool3_1_0_split
I1031 22:16:37.054116  7887 net.cpp:410] pool3_1_pool3_1_0_split <- pool3_1
I1031 22:16:37.054128  7887 net.cpp:368] pool3_1_pool3_1_0_split -> pool3_1_pool3_1_0_split_0
I1031 22:16:37.054143  7887 net.cpp:368] pool3_1_pool3_1_0_split -> pool3_1_pool3_1_0_split_1
I1031 22:16:37.054157  7887 net.cpp:120] Setting up pool3_1_pool3_1_0_split
I1031 22:16:37.054386  7887 net.cpp:127] Top shape: 32 60 7 7 (94080)
I1031 22:16:37.054404  7887 net.cpp:127] Top shape: 32 60 7 7 (94080)
I1031 22:16:37.054415  7887 layer_factory.hpp:74] Creating layer conv4_1
I1031 22:16:37.054430  7887 net.cpp:90] Creating Layer conv4_1
I1031 22:16:37.054441  7887 net.cpp:410] conv4_1 <- pool3_1_pool3_1_0_split_0
I1031 22:16:37.054460  7887 net.cpp:368] conv4_1 -> conv4_1
I1031 22:16:37.054476  7887 net.cpp:120] Setting up conv4_1
I1031 22:16:37.055219  7887 net.cpp:127] Top shape: 32 80 3 3 (23040)
I1031 22:16:37.055238  7887 layer_factory.hpp:74] Creating layer flatten_pool3_1
I1031 22:16:37.055255  7887 net.cpp:90] Creating Layer flatten_pool3_1
I1031 22:16:37.055268  7887 net.cpp:410] flatten_pool3_1 <- pool3_1_pool3_1_0_split_1
I1031 22:16:37.055282  7887 net.cpp:368] flatten_pool3_1 -> flatten_pool3_1
I1031 22:16:37.055296  7887 net.cpp:120] Setting up flatten_pool3_1
I1031 22:16:37.055311  7887 net.cpp:127] Top shape: 32 2940 (94080)
I1031 22:16:37.055323  7887 layer_factory.hpp:74] Creating layer flatten_conv4_1
I1031 22:16:37.055335  7887 net.cpp:90] Creating Layer flatten_conv4_1
I1031 22:16:37.055346  7887 net.cpp:410] flatten_conv4_1 <- conv4_1
I1031 22:16:37.055358  7887 net.cpp:368] flatten_conv4_1 -> flatten_conv4_1
I1031 22:16:37.055371  7887 net.cpp:120] Setting up flatten_conv4_1
I1031 22:16:37.055384  7887 net.cpp:127] Top shape: 32 720 (23040)
I1031 22:16:37.055395  7887 layer_factory.hpp:74] Creating layer contact_conv
I1031 22:16:37.055409  7887 net.cpp:90] Creating Layer contact_conv
I1031 22:16:37.055420  7887 net.cpp:410] contact_conv <- flatten_conv4_1
I1031 22:16:37.055434  7887 net.cpp:410] contact_conv <- flatten_pool3_1
I1031 22:16:37.055460  7887 net.cpp:368] contact_conv -> contact_conv
I1031 22:16:37.055474  7887 net.cpp:120] Setting up contact_conv
I1031 22:16:37.055492  7887 net.cpp:127] Top shape: 32 3660 (117120)
I1031 22:16:37.055503  7887 layer_factory.hpp:74] Creating layer deepid_1
I1031 22:16:37.055521  7887 net.cpp:90] Creating Layer deepid_1
I1031 22:16:37.055532  7887 net.cpp:410] deepid_1 <- contact_conv
I1031 22:16:37.055546  7887 net.cpp:368] deepid_1 -> deepid_1
I1031 22:16:37.055564  7887 net.cpp:120] Setting up deepid_1
I1031 22:16:37.069577  7887 net.cpp:127] Top shape: 32 160 (5120)
I1031 22:16:37.069597  7887 layer_factory.hpp:74] Creating layer relu6_1
I1031 22:16:37.069605  7887 net.cpp:90] Creating Layer relu6_1
I1031 22:16:37.069612  7887 net.cpp:410] relu6_1 <- deepid_1
I1031 22:16:37.069619  7887 net.cpp:357] relu6_1 -> deepid_1 (in-place)
I1031 22:16:37.069628  7887 net.cpp:120] Setting up relu6_1
I1031 22:16:37.069634  7887 net.cpp:127] Top shape: 32 160 (5120)
I1031 22:16:37.069640  7887 layer_factory.hpp:74] Creating layer drop6_1
I1031 22:16:37.069649  7887 net.cpp:90] Creating Layer drop6_1
I1031 22:16:37.069655  7887 net.cpp:410] drop6_1 <- deepid_1
I1031 22:16:37.069664  7887 net.cpp:357] drop6_1 -> deepid_1 (in-place)
I1031 22:16:37.069672  7887 net.cpp:120] Setting up drop6_1
I1031 22:16:37.069682  7887 net.cpp:127] Top shape: 32 160 (5120)
I1031 22:16:37.069689  7887 layer_factory.hpp:74] Creating layer fc8_1
I1031 22:16:37.069696  7887 net.cpp:90] Creating Layer fc8_1
I1031 22:16:37.069702  7887 net.cpp:410] fc8_1 <- deepid_1
I1031 22:16:37.069711  7887 net.cpp:368] fc8_1 -> fc8_1
I1031 22:16:37.069720  7887 net.cpp:120] Setting up fc8_1
I1031 22:16:37.106751  7887 net.cpp:127] Top shape: 32 10575 (338400)
I1031 22:16:37.106775  7887 layer_factory.hpp:74] Creating layer loss_1
I1031 22:16:37.106789  7887 net.cpp:90] Creating Layer loss_1
I1031 22:16:37.106796  7887 net.cpp:410] loss_1 <- fc8_1
I1031 22:16:37.106804  7887 net.cpp:410] loss_1 <- label_1
I1031 22:16:37.106813  7887 net.cpp:368] loss_1 -> loss_1
I1031 22:16:37.106829  7887 net.cpp:120] Setting up loss_1
I1031 22:16:37.106839  7887 layer_factory.hpp:74] Creating layer loss_1
I1031 22:16:37.107486  7887 net.cpp:127] Top shape: (1)
I1031 22:16:37.107497  7887 net.cpp:129]     with loss weight 1
I1031 22:16:37.107519  7887 net.cpp:192] loss_1 needs backward computation.
I1031 22:16:37.107542  7887 net.cpp:192] fc8_1 needs backward computation.
I1031 22:16:37.107563  7887 net.cpp:192] drop6_1 needs backward computation.
I1031 22:16:37.107575  7887 net.cpp:192] relu6_1 needs backward computation.
I1031 22:16:37.107583  7887 net.cpp:192] deepid_1 needs backward computation.
I1031 22:16:37.107592  7887 net.cpp:192] contact_conv needs backward computation.
I1031 22:16:37.107605  7887 net.cpp:192] flatten_conv4_1 needs backward computation.
I1031 22:16:37.107614  7887 net.cpp:192] flatten_pool3_1 needs backward computation.
I1031 22:16:37.107625  7887 net.cpp:192] conv4_1 needs backward computation.
I1031 22:16:37.107635  7887 net.cpp:192] pool3_1_pool3_1_0_split needs backward computation.
I1031 22:16:37.107646  7887 net.cpp:192] pool3_1 needs backward computation.
I1031 22:16:37.107655  7887 net.cpp:192] conv3_1 needs backward computation.
I1031 22:16:37.107661  7887 net.cpp:192] pool2_1 needs backward computation.
I1031 22:16:37.107668  7887 net.cpp:192] norm2_1 needs backward computation.
I1031 22:16:37.107677  7887 net.cpp:192] relu2_1 needs backward computation.
I1031 22:16:37.107686  7887 net.cpp:192] conv2_1 needs backward computation.
I1031 22:16:37.107695  7887 net.cpp:192] pool1_1 needs backward computation.
I1031 22:16:37.107703  7887 net.cpp:192] norm1_1 needs backward computation.
I1031 22:16:37.107712  7887 net.cpp:192] relu1_1 needs backward computation.
I1031 22:16:37.107720  7887 net.cpp:192] conv1_1 needs backward computation.
I1031 22:16:37.107728  7887 net.cpp:194] data_1 does not need backward computation.
I1031 22:16:37.107736  7887 net.cpp:235] This network produces output loss_1
I1031 22:16:37.107777  7887 net.cpp:482] Collecting Learning Rate and Weight Decay.
I1031 22:16:37.107791  7887 net.cpp:247] Network initialization done.
I1031 22:16:37.107802  7887 net.cpp:248] Memory required for data: 51551236
I1031 22:16:37.108435  7887 solver.cpp:154] Creating test net (#0) specified by net file: FaceRecognition/try5_2/train_val.prototxt
I1031 22:16:37.108471  7887 net.cpp:287] The NetState phase (1) differed from the phase (0) specified by a rule in layer data_1
I1031 22:16:37.108582  7887 net.cpp:42] Initializing net from parameters: 
name: "face_train_val"
state {
  phase: TEST
}
layer {
  name: "data_1"
  type: "Data"
  top: "data_1"
  top: "label_1"
  include {
    phase: TEST
  }
  transform_param {
    mirror: true
    mean_file: "/media/crw/MyBook/TrainData/LMDB/CASIA-WebFace/10575_64X64/mean.binaryproto"
  }
  data_param {
    source: "/media/crw/MyBook/TrainData/LMDB/CASIA-WebFace/10575_64X64/val"
    batch_size: 32
    backend: LMDB
  }
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "data_1"
  top: "conv1_1"
  param {
    name: "conv1_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv1_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 20
    kernel_size: 4
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1"
  top: "conv1_1"
}
layer {
  name: "norm1_1"
  type: "LRN"
  bottom: "conv1_1"
  top: "norm1_1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool1_1"
  type: "Pooling"
  bottom: "norm1_1"
  top: "pool1_1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1_1"
  top: "conv2_1"
  param {
    name: "conv2_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv2_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 40
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "norm2_1"
  type: "LRN"
  bottom: "conv2_1"
  top: "norm2_1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool2_1"
  type: "Pooling"
  bottom: "norm2_1"
  top: "pool2_1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2_1"
  top: "conv3_1"
  param {
    name: "conv3_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv3_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 60
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "pool3_1"
  type: "Pooling"
  bottom: "conv3_1"
  top: "pool3_1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3_1"
  top: "conv4_1"
  param {
    name: "conv4_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv4_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 80
    kernel_size: 2
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "flatten_pool3_1"
  type: "Flatten"
  bottom: "pool3_1"
  top: "flatten_pool3_1"
}
layer {
  name: "flatten_conv4_1"
  type: "Flatten"
  bottom: "conv4_1"
  top: "flatten_conv4_1"
}
layer {
  name: "contact_conv"
  type: "Concat"
  bottom: "flatten_conv4_1"
  bottom: "flatten_pool3_1"
  top: "contact_conv"
}
layer {
  name: "deepid_1"
  type: "InnerProduct"
  bottom: "contact_conv"
  top: "deepid_1"
  param {
    name: "fc6_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "fc6_b"
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 160
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6_1"
  type: "ReLU"
  bottom: "deepid_1"
  top: "deepid_1"
}
layer {
  name: "drop6_1"
  type: "Dropout"
  bottom: "deepid_1"
  top: "deepid_1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8_1"
  type: "InnerProduct"
  bottom: "deepid_1"
  top: "fc8_1"
  param {
    name: "fc8_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "fc8_b"
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 10575
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "accuracy_1"
  type: "Accuracy"
  bottom: "fc8_1"
  bottom: "label_1"
  top: "accuracy_1"
  include {
    phase: TEST
  }
}
layer {
  name: "loss_1"
  type: "SoftmaxWithLoss"
  bottom: "fc8_1"
  bottom: "label_1"
  top: "loss_1"
}
I1031 22:16:37.109320  7887 layer_factory.hpp:74] Creating layer data_1
I1031 22:16:37.109333  7887 net.cpp:90] Creating Layer data_1
I1031 22:16:37.109341  7887 net.cpp:368] data_1 -> data_1
I1031 22:16:37.109350  7887 net.cpp:368] data_1 -> label_1
I1031 22:16:37.109359  7887 net.cpp:120] Setting up data_1
I1031 22:16:37.109565  7887 db.cpp:34] Opened lmdb /media/crw/MyBook/TrainData/LMDB/CASIA-WebFace/10575_64X64/val
I1031 22:16:37.109673  7887 data_layer.cpp:67] output data size: 32,3,64,64
I1031 22:16:37.109683  7887 data_transformer.cpp:22] Loading mean file from: /media/crw/MyBook/TrainData/LMDB/CASIA-WebFace/10575_64X64/mean.binaryproto
I1031 22:16:37.110184  7887 net.cpp:127] Top shape: 32 3 64 64 (393216)
I1031 22:16:37.110196  7887 net.cpp:127] Top shape: 32 (32)
I1031 22:16:37.110203  7887 layer_factory.hpp:74] Creating layer label_1_data_1_1_split
I1031 22:16:37.110211  7887 net.cpp:90] Creating Layer label_1_data_1_1_split
I1031 22:16:37.110225  7887 net.cpp:410] label_1_data_1_1_split <- label_1
I1031 22:16:37.110234  7887 net.cpp:368] label_1_data_1_1_split -> label_1_data_1_1_split_0
I1031 22:16:37.110242  7887 net.cpp:368] label_1_data_1_1_split -> label_1_data_1_1_split_1
I1031 22:16:37.110250  7887 net.cpp:120] Setting up label_1_data_1_1_split
I1031 22:16:37.110258  7887 net.cpp:127] Top shape: 32 (32)
I1031 22:16:37.110265  7887 net.cpp:127] Top shape: 32 (32)
I1031 22:16:37.110275  7887 layer_factory.hpp:74] Creating layer conv1_1
I1031 22:16:37.110285  7887 net.cpp:90] Creating Layer conv1_1
I1031 22:16:37.110291  7887 net.cpp:410] conv1_1 <- data_1
I1031 22:16:37.110299  7887 net.cpp:368] conv1_1 -> conv1_1
I1031 22:16:37.110308  7887 net.cpp:120] Setting up conv1_1
I1031 22:16:37.110348  7887 net.cpp:127] Top shape: 32 20 61 61 (2381440)
I1031 22:16:37.110358  7887 layer_factory.hpp:74] Creating layer relu1_1
I1031 22:16:37.110365  7887 net.cpp:90] Creating Layer relu1_1
I1031 22:16:37.110371  7887 net.cpp:410] relu1_1 <- conv1_1
I1031 22:16:37.110378  7887 net.cpp:357] relu1_1 -> conv1_1 (in-place)
I1031 22:16:37.110385  7887 net.cpp:120] Setting up relu1_1
I1031 22:16:37.110393  7887 net.cpp:127] Top shape: 32 20 61 61 (2381440)
I1031 22:16:37.110399  7887 layer_factory.hpp:74] Creating layer norm1_1
I1031 22:16:37.110407  7887 net.cpp:90] Creating Layer norm1_1
I1031 22:16:37.110414  7887 net.cpp:410] norm1_1 <- conv1_1
I1031 22:16:37.110420  7887 net.cpp:368] norm1_1 -> norm1_1
I1031 22:16:37.110427  7887 net.cpp:120] Setting up norm1_1
I1031 22:16:37.110435  7887 net.cpp:127] Top shape: 32 20 61 61 (2381440)
I1031 22:16:37.110441  7887 layer_factory.hpp:74] Creating layer pool1_1
I1031 22:16:37.110448  7887 net.cpp:90] Creating Layer pool1_1
I1031 22:16:37.110455  7887 net.cpp:410] pool1_1 <- norm1_1
I1031 22:16:37.110461  7887 net.cpp:368] pool1_1 -> pool1_1
I1031 22:16:37.110468  7887 net.cpp:120] Setting up pool1_1
I1031 22:16:37.110482  7887 net.cpp:127] Top shape: 32 20 31 31 (615040)
I1031 22:16:37.110489  7887 layer_factory.hpp:74] Creating layer conv2_1
I1031 22:16:37.110505  7887 net.cpp:90] Creating Layer conv2_1
I1031 22:16:37.110512  7887 net.cpp:410] conv2_1 <- pool1_1
I1031 22:16:37.110519  7887 net.cpp:368] conv2_1 -> conv2_1
I1031 22:16:37.110527  7887 net.cpp:120] Setting up conv2_1
I1031 22:16:37.110615  7887 net.cpp:127] Top shape: 32 40 29 29 (1076480)
I1031 22:16:37.110623  7887 layer_factory.hpp:74] Creating layer relu2_1
I1031 22:16:37.110632  7887 net.cpp:90] Creating Layer relu2_1
I1031 22:16:37.110638  7887 net.cpp:410] relu2_1 <- conv2_1
I1031 22:16:37.110646  7887 net.cpp:357] relu2_1 -> conv2_1 (in-place)
I1031 22:16:37.110652  7887 net.cpp:120] Setting up relu2_1
I1031 22:16:37.110659  7887 net.cpp:127] Top shape: 32 40 29 29 (1076480)
I1031 22:16:37.110666  7887 layer_factory.hpp:74] Creating layer norm2_1
I1031 22:16:37.110672  7887 net.cpp:90] Creating Layer norm2_1
I1031 22:16:37.110679  7887 net.cpp:410] norm2_1 <- conv2_1
I1031 22:16:37.110685  7887 net.cpp:368] norm2_1 -> norm2_1
I1031 22:16:37.110693  7887 net.cpp:120] Setting up norm2_1
I1031 22:16:37.110702  7887 net.cpp:127] Top shape: 32 40 29 29 (1076480)
I1031 22:16:37.110707  7887 layer_factory.hpp:74] Creating layer pool2_1
I1031 22:16:37.110715  7887 net.cpp:90] Creating Layer pool2_1
I1031 22:16:37.110721  7887 net.cpp:410] pool2_1 <- norm2_1
I1031 22:16:37.110728  7887 net.cpp:368] pool2_1 -> pool2_1
I1031 22:16:37.110735  7887 net.cpp:120] Setting up pool2_1
I1031 22:16:37.110743  7887 net.cpp:127] Top shape: 32 40 15 15 (288000)
I1031 22:16:37.110749  7887 layer_factory.hpp:74] Creating layer conv3_1
I1031 22:16:37.110756  7887 net.cpp:90] Creating Layer conv3_1
I1031 22:16:37.110762  7887 net.cpp:410] conv3_1 <- pool2_1
I1031 22:16:37.110769  7887 net.cpp:368] conv3_1 -> conv3_1
I1031 22:16:37.110776  7887 net.cpp:120] Setting up conv3_1
I1031 22:16:37.111234  7887 net.cpp:127] Top shape: 32 60 13 13 (324480)
I1031 22:16:37.111245  7887 layer_factory.hpp:74] Creating layer pool3_1
I1031 22:16:37.111253  7887 net.cpp:90] Creating Layer pool3_1
I1031 22:16:37.111259  7887 net.cpp:410] pool3_1 <- conv3_1
I1031 22:16:37.111266  7887 net.cpp:368] pool3_1 -> pool3_1
I1031 22:16:37.111274  7887 net.cpp:120] Setting up pool3_1
I1031 22:16:37.111282  7887 net.cpp:127] Top shape: 32 60 7 7 (94080)
I1031 22:16:37.111289  7887 layer_factory.hpp:74] Creating layer pool3_1_pool3_1_0_split
I1031 22:16:37.111296  7887 net.cpp:90] Creating Layer pool3_1_pool3_1_0_split
I1031 22:16:37.111302  7887 net.cpp:410] pool3_1_pool3_1_0_split <- pool3_1
I1031 22:16:37.111310  7887 net.cpp:368] pool3_1_pool3_1_0_split -> pool3_1_pool3_1_0_split_0
I1031 22:16:37.111316  7887 net.cpp:368] pool3_1_pool3_1_0_split -> pool3_1_pool3_1_0_split_1
I1031 22:16:37.111325  7887 net.cpp:120] Setting up pool3_1_pool3_1_0_split
I1031 22:16:37.111333  7887 net.cpp:127] Top shape: 32 60 7 7 (94080)
I1031 22:16:37.111340  7887 net.cpp:127] Top shape: 32 60 7 7 (94080)
I1031 22:16:37.111346  7887 layer_factory.hpp:74] Creating layer conv4_1
I1031 22:16:37.111353  7887 net.cpp:90] Creating Layer conv4_1
I1031 22:16:37.111359  7887 net.cpp:410] conv4_1 <- pool3_1_pool3_1_0_split_0
I1031 22:16:37.111368  7887 net.cpp:368] conv4_1 -> conv4_1
I1031 22:16:37.111377  7887 net.cpp:120] Setting up conv4_1
I1031 22:16:37.111770  7887 net.cpp:127] Top shape: 32 80 3 3 (23040)
I1031 22:16:37.111779  7887 layer_factory.hpp:74] Creating layer flatten_pool3_1
I1031 22:16:37.111786  7887 net.cpp:90] Creating Layer flatten_pool3_1
I1031 22:16:37.111793  7887 net.cpp:410] flatten_pool3_1 <- pool3_1_pool3_1_0_split_1
I1031 22:16:37.111799  7887 net.cpp:368] flatten_pool3_1 -> flatten_pool3_1
I1031 22:16:37.111807  7887 net.cpp:120] Setting up flatten_pool3_1
I1031 22:16:37.111814  7887 net.cpp:127] Top shape: 32 2940 (94080)
I1031 22:16:37.111821  7887 layer_factory.hpp:74] Creating layer flatten_conv4_1
I1031 22:16:37.111829  7887 net.cpp:90] Creating Layer flatten_conv4_1
I1031 22:16:37.111834  7887 net.cpp:410] flatten_conv4_1 <- conv4_1
I1031 22:16:37.111840  7887 net.cpp:368] flatten_conv4_1 -> flatten_conv4_1
I1031 22:16:37.111855  7887 net.cpp:120] Setting up flatten_conv4_1
I1031 22:16:37.111863  7887 net.cpp:127] Top shape: 32 720 (23040)
I1031 22:16:37.111871  7887 layer_factory.hpp:74] Creating layer contact_conv
I1031 22:16:37.111879  7887 net.cpp:90] Creating Layer contact_conv
I1031 22:16:37.111886  7887 net.cpp:410] contact_conv <- flatten_conv4_1
I1031 22:16:37.111891  7887 net.cpp:410] contact_conv <- flatten_pool3_1
I1031 22:16:37.111898  7887 net.cpp:368] contact_conv -> contact_conv
I1031 22:16:37.111906  7887 net.cpp:120] Setting up contact_conv
I1031 22:16:37.111914  7887 net.cpp:127] Top shape: 32 3660 (117120)
I1031 22:16:37.111920  7887 layer_factory.hpp:74] Creating layer deepid_1
I1031 22:16:37.111928  7887 net.cpp:90] Creating Layer deepid_1
I1031 22:16:37.111934  7887 net.cpp:410] deepid_1 <- contact_conv
I1031 22:16:37.111942  7887 net.cpp:368] deepid_1 -> deepid_1
I1031 22:16:37.111949  7887 net.cpp:120] Setting up deepid_1
I1031 22:16:37.124069  7887 net.cpp:127] Top shape: 32 160 (5120)
I1031 22:16:37.124089  7887 layer_factory.hpp:74] Creating layer relu6_1
I1031 22:16:37.124099  7887 net.cpp:90] Creating Layer relu6_1
I1031 22:16:37.124105  7887 net.cpp:410] relu6_1 <- deepid_1
I1031 22:16:37.124114  7887 net.cpp:357] relu6_1 -> deepid_1 (in-place)
I1031 22:16:37.124121  7887 net.cpp:120] Setting up relu6_1
I1031 22:16:37.124128  7887 net.cpp:127] Top shape: 32 160 (5120)
I1031 22:16:37.124135  7887 layer_factory.hpp:74] Creating layer drop6_1
I1031 22:16:37.124142  7887 net.cpp:90] Creating Layer drop6_1
I1031 22:16:37.124148  7887 net.cpp:410] drop6_1 <- deepid_1
I1031 22:16:37.124155  7887 net.cpp:357] drop6_1 -> deepid_1 (in-place)
I1031 22:16:37.124161  7887 net.cpp:120] Setting up drop6_1
I1031 22:16:37.124169  7887 net.cpp:127] Top shape: 32 160 (5120)
I1031 22:16:37.124176  7887 layer_factory.hpp:74] Creating layer fc8_1
I1031 22:16:37.124186  7887 net.cpp:90] Creating Layer fc8_1
I1031 22:16:37.124191  7887 net.cpp:410] fc8_1 <- deepid_1
I1031 22:16:37.124200  7887 net.cpp:368] fc8_1 -> fc8_1
I1031 22:16:37.124208  7887 net.cpp:120] Setting up fc8_1
I1031 22:16:37.159489  7887 net.cpp:127] Top shape: 32 10575 (338400)
I1031 22:16:37.159513  7887 layer_factory.hpp:74] Creating layer fc8_1_fc8_1_0_split
I1031 22:16:37.159525  7887 net.cpp:90] Creating Layer fc8_1_fc8_1_0_split
I1031 22:16:37.159533  7887 net.cpp:410] fc8_1_fc8_1_0_split <- fc8_1
I1031 22:16:37.159541  7887 net.cpp:368] fc8_1_fc8_1_0_split -> fc8_1_fc8_1_0_split_0
I1031 22:16:37.159551  7887 net.cpp:368] fc8_1_fc8_1_0_split -> fc8_1_fc8_1_0_split_1
I1031 22:16:37.159559  7887 net.cpp:120] Setting up fc8_1_fc8_1_0_split
I1031 22:16:37.159569  7887 net.cpp:127] Top shape: 32 10575 (338400)
I1031 22:16:37.159575  7887 net.cpp:127] Top shape: 32 10575 (338400)
I1031 22:16:37.159581  7887 layer_factory.hpp:74] Creating layer accuracy_1
I1031 22:16:37.159590  7887 net.cpp:90] Creating Layer accuracy_1
I1031 22:16:37.159596  7887 net.cpp:410] accuracy_1 <- fc8_1_fc8_1_0_split_0
I1031 22:16:37.159602  7887 net.cpp:410] accuracy_1 <- label_1_data_1_1_split_0
I1031 22:16:37.159610  7887 net.cpp:368] accuracy_1 -> accuracy_1
I1031 22:16:37.159618  7887 net.cpp:120] Setting up accuracy_1
I1031 22:16:37.159631  7887 net.cpp:127] Top shape: (1)
I1031 22:16:37.159636  7887 layer_factory.hpp:74] Creating layer loss_1
I1031 22:16:37.159644  7887 net.cpp:90] Creating Layer loss_1
I1031 22:16:37.159651  7887 net.cpp:410] loss_1 <- fc8_1_fc8_1_0_split_1
I1031 22:16:37.159657  7887 net.cpp:410] loss_1 <- label_1_data_1_1_split_1
I1031 22:16:37.159665  7887 net.cpp:368] loss_1 -> loss_1
I1031 22:16:37.159672  7887 net.cpp:120] Setting up loss_1
I1031 22:16:37.159680  7887 layer_factory.hpp:74] Creating layer loss_1
I1031 22:16:37.160095  7887 net.cpp:127] Top shape: (1)
I1031 22:16:37.160104  7887 net.cpp:129]     with loss weight 1
I1031 22:16:37.160115  7887 net.cpp:192] loss_1 needs backward computation.
I1031 22:16:37.160121  7887 net.cpp:194] accuracy_1 does not need backward computation.
I1031 22:16:37.160127  7887 net.cpp:192] fc8_1_fc8_1_0_split needs backward computation.
I1031 22:16:37.160147  7887 net.cpp:192] fc8_1 needs backward computation.
I1031 22:16:37.160154  7887 net.cpp:192] drop6_1 needs backward computation.
I1031 22:16:37.160161  7887 net.cpp:192] relu6_1 needs backward computation.
I1031 22:16:37.160166  7887 net.cpp:192] deepid_1 needs backward computation.
I1031 22:16:37.160172  7887 net.cpp:192] contact_conv needs backward computation.
I1031 22:16:37.160178  7887 net.cpp:192] flatten_conv4_1 needs backward computation.
I1031 22:16:37.160184  7887 net.cpp:192] flatten_pool3_1 needs backward computation.
I1031 22:16:37.160190  7887 net.cpp:192] conv4_1 needs backward computation.
I1031 22:16:37.160197  7887 net.cpp:192] pool3_1_pool3_1_0_split needs backward computation.
I1031 22:16:37.160202  7887 net.cpp:192] pool3_1 needs backward computation.
I1031 22:16:37.160209  7887 net.cpp:192] conv3_1 needs backward computation.
I1031 22:16:37.160214  7887 net.cpp:192] pool2_1 needs backward computation.
I1031 22:16:37.160220  7887 net.cpp:192] norm2_1 needs backward computation.
I1031 22:16:37.160226  7887 net.cpp:192] relu2_1 needs backward computation.
I1031 22:16:37.160233  7887 net.cpp:192] conv2_1 needs backward computation.
I1031 22:16:37.160238  7887 net.cpp:192] pool1_1 needs backward computation.
I1031 22:16:37.160244  7887 net.cpp:192] norm1_1 needs backward computation.
I1031 22:16:37.160250  7887 net.cpp:192] relu1_1 needs backward computation.
I1031 22:16:37.160256  7887 net.cpp:192] conv1_1 needs backward computation.
I1031 22:16:37.160262  7887 net.cpp:194] label_1_data_1_1_split does not need backward computation.
I1031 22:16:37.160269  7887 net.cpp:194] data_1 does not need backward computation.
I1031 22:16:37.160274  7887 net.cpp:235] This network produces output accuracy_1
I1031 22:16:37.160280  7887 net.cpp:235] This network produces output loss_1
I1031 22:16:37.160298  7887 net.cpp:482] Collecting Learning Rate and Weight Decay.
I1031 22:16:37.160307  7887 net.cpp:247] Network initialization done.
I1031 22:16:37.160313  7887 net.cpp:248] Memory required for data: 54258696
I1031 22:16:37.160387  7887 solver.cpp:42] Solver scaffolding done.
I1031 22:16:37.160413  7887 solver.cpp:225] Solving face_train_val
I1031 22:16:37.160418  7887 solver.cpp:226] Learning Rate Policy: step
I1031 22:16:37.160428  7887 solver.cpp:269] Iteration 0, Testing net (#0)
I1031 22:16:38.488569  7887 solver.cpp:318]     Test net output #0: accuracy_1 = 0
I1031 22:16:38.488598  7887 solver.cpp:318]     Test net output #1: loss_1 = 9.26664 (* 1 = 9.26664 loss)
I1031 22:16:38.536919  7887 solver.cpp:189] Iteration 0, loss = 9.26728
I1031 22:16:38.536948  7887 solver.cpp:204]     Train net output #0: loss_1 = 9.26728 (* 1 = 9.26728 loss)
I1031 22:16:38.536964  7887 solver.cpp:461] Iteration 0, lr = 0.001
I1031 22:16:41.753705  7887 solver.cpp:189] Iteration 100, loss = 9.2674
I1031 22:16:41.753734  7887 solver.cpp:204]     Train net output #0: loss_1 = 9.2674 (* 1 = 9.2674 loss)
I1031 22:16:41.753744  7887 solver.cpp:461] Iteration 100, lr = 0.001
I1031 22:16:45.043472  7887 solver.cpp:189] Iteration 200, loss = 9.26238
I1031 22:16:45.043503  7887 solver.cpp:204]     Train net output #0: loss_1 = 9.26238 (* 1 = 9.26238 loss)
I1031 22:16:45.043514  7887 solver.cpp:461] Iteration 200, lr = 0.001
I1031 22:16:48.223542  7887 solver.cpp:189] Iteration 300, loss = 9.27072
I1031 22:16:48.223569  7887 solver.cpp:204]     Train net output #0: loss_1 = 9.27072 (* 1 = 9.27072 loss)
I1031 22:16:48.223578  7887 solver.cpp:461] Iteration 300, lr = 0.001
I1031 22:16:51.379375  7887 solver.cpp:189] Iteration 400, loss = 9.26389
I1031 22:16:51.379403  7887 solver.cpp:204]     Train net output #0: loss_1 = 9.26389 (* 1 = 9.26389 loss)
I1031 22:16:51.379412  7887 solver.cpp:461] Iteration 400, lr = 0.001
I1031 22:16:54.538532  7887 solver.cpp:189] Iteration 500, loss = 9.26347
I1031 22:16:54.538560  7887 solver.cpp:204]     Train net output #0: loss_1 = 9.26347 (* 1 = 9.26347 loss)
I1031 22:16:54.538569  7887 solver.cpp:461] Iteration 500, lr = 0.001
I1031 22:16:57.710140  7887 solver.cpp:189] Iteration 600, loss = 9.2575
I1031 22:16:57.710188  7887 solver.cpp:204]     Train net output #0: loss_1 = 9.2575 (* 1 = 9.2575 loss)
I1031 22:16:57.710199  7887 solver.cpp:461] Iteration 600, lr = 0.001
I1031 22:17:00.858526  7887 solver.cpp:189] Iteration 700, loss = 9.26539
I1031 22:17:00.858558  7887 solver.cpp:204]     Train net output #0: loss_1 = 9.26539 (* 1 = 9.26539 loss)
I1031 22:17:00.858572  7887 solver.cpp:461] Iteration 700, lr = 0.001
I1031 22:17:04.003823  7887 solver.cpp:189] Iteration 800, loss = 9.26271
I1031 22:17:04.003854  7887 solver.cpp:204]     Train net output #0: loss_1 = 9.26271 (* 1 = 9.26271 loss)
I1031 22:17:04.003868  7887 solver.cpp:461] Iteration 800, lr = 0.001
I1031 22:17:07.148654  7887 solver.cpp:189] Iteration 900, loss = 9.25997
